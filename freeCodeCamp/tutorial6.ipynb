{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da08f7b",
   "metadata": {},
   "source": [
    "**1. Import the required class from PySpark to create a SparkSession.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b35034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264bae6",
   "metadata": {},
   "source": [
    "**2. Write the statement to create a SparkSession with an appropriate application name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "791c999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Tutorial 6\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755de86",
   "metadata": {},
   "source": [
    "**3. Display the SparkSession object in the Jupyter Notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95876211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://WIN-TBM2Q8JSFF6.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Tutorial 6</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x285dcc9d8d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1367b54",
   "metadata": {},
   "source": [
    "**4. Write the command used to read a CSV file into a PySpark DataFrame with the header option enabled.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b697989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('test1.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcdb31",
   "metadata": {},
   "source": [
    "**5. Display the contents of the DataFrame after loading the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a87faa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c4572",
   "metadata": {},
   "source": [
    "**6. Write the statement used to check the schema of the DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e164aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836f462",
   "metadata": {},
   "source": [
    "**7. Import the required PySpark ML class to convert categorical string columns into numeric form.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70390ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ade07b",
   "metadata": {},
   "source": [
    "**8. Write the command used to apply StringIndexer on a categorical column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2435cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = StringIndexer(inputCol=\"Name\",outputCol=\"NameIndex\")\n",
    "df_name_indexed = ir.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74be1dd",
   "metadata": {},
   "source": [
    "**9. Write the statement used to display the transformed DataFrame after applying StringIndexer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08c5bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+---------+\n",
      "|     Name|age|Experience|Salary|NameIndex|\n",
      "+---------+---+----------+------+---------+\n",
      "|    Krish| 31|        10| 30000|      1.0|\n",
      "|Sudhanshu| 30|         8| 25000|      4.0|\n",
      "|    Sunny| 29|         4| 20000|      5.0|\n",
      "|     Paul| 24|         3| 20000|      2.0|\n",
      "|   Harsha| 21|         1| 15000|      0.0|\n",
      "|  Shubham| 23|         2| 18000|      3.0|\n",
      "+---------+---+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_name_indexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71eb958",
   "metadata": {},
   "source": [
    "**10. Import the required class used to assemble multiple input columns into a single feature vector.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e00ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9dab3e",
   "metadata": {},
   "source": [
    "**11. Write the command used to create a VectorAssembler with the specified input columns and output column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "914d8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=[\"age\",\"Experience\"],outputCol=\"Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1f1fb",
   "metadata": {},
   "source": [
    "**12. Write the statement used to transform the DataFrame using VectorAssembler.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "911ee3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|      Input|Salary|\n",
      "+-----------+------+\n",
      "|[31.0,10.0]| 30000|\n",
      "| [30.0,8.0]| 25000|\n",
      "| [29.0,4.0]| 20000|\n",
      "| [24.0,3.0]| 20000|\n",
      "| [21.0,1.0]| 15000|\n",
      "| [23.0,2.0]| 18000|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed = va.transform(df_name_indexed)\n",
    "df_modified = df_transformed.select(\"Input\",\"Salary\")\n",
    "df_modified.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7062ada5",
   "metadata": {},
   "source": [
    "**13. Import the required PySpark ML class to build a regression model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38951ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20bd74e",
   "metadata": {},
   "source": [
    "**14. Write the statement used to create a Linear Regression model with the specified features and label columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a1e1692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|      Input|Salary|\n",
      "+-----------+------+\n",
      "| [23.0,2.0]| 18000|\n",
      "| [24.0,3.0]| 20000|\n",
      "| [29.0,4.0]| 20000|\n",
      "| [30.0,8.0]| 25000|\n",
      "|[31.0,10.0]| 30000|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df_modified.randomSplit(weights=[0.75,0.25])\n",
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01f3a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"Input\",labelCol=\"Salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ecf16",
   "metadata": {},
   "source": [
    "**15. Write the command used to fit (train) the Linear Regression model on the prepared DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1fd00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1071e62",
   "metadata": {},
   "source": [
    "**16. Write the statement used to display the model coefficients and intercept.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6666f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-323.28668819526484,1696.8066020811573]\n",
      "22295.299605312008\n"
     ]
    }
   ],
   "source": [
    "print(model.coefficients)\n",
    "print(model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5fd3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|     Input|Salary|\n",
      "+----------+------+\n",
      "|[21.0,1.0]| 15000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04b38d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------------------+\n",
      "|     Input|Salary|        prediction|\n",
      "+----------+------+------------------+\n",
      "|[21.0,1.0]| 15000|17203.085755292603|\n",
      "+----------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(test_data)\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3903a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
