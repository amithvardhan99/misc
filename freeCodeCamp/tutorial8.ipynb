{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7134cb",
   "metadata": {},
   "source": [
    "**1. Import the required class from PySpark to create a SparkSession.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81c37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b4c34",
   "metadata": {},
   "source": [
    "**2. Write the statement to create a SparkSession with a suitable application name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e789fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Tutorial 8\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568dc20",
   "metadata": {},
   "source": [
    "**3. Display the SparkSession object in the Jupyter Notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e49b80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://WIN-TBM2Q8JSFF6.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Tutorial 8</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25cb91a5990>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5f847",
   "metadata": {},
   "source": [
    "**4. Write the command used to read a CSV file into a PySpark DataFrame with the header option enabled.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0671bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"tips.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb20ded",
   "metadata": {},
   "source": [
    "**5. Display the contents of the DataFrame after loading the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f7cb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33ea5c",
   "metadata": {},
   "source": [
    "**6. Write the statement used to check the schema of the DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afebc213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7782a3c",
   "metadata": {},
   "source": [
    "**7. Import the required PySpark ML class used to convert categorical string columns into numerical values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5fa432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e4faf",
   "metadata": {},
   "source": [
    "**8. Write the command used to apply StringIndexer on the categorical column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1fddaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a5c52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si = StringIndexer(inputCol=[\"sex\",\"smoker\",\"day\",\"time\"],outputCol=[\"sex_indexed\",\"smoker_indexed\",\"day_indexed\",\"time_indexed\"])\n",
    "\n",
    "si = StringIndexer(inputCol=\"sex\",outputCol=\"sex_indexed\")\n",
    "df_transformed = si.fit(df).transform(df)\n",
    "\n",
    "si = StringIndexer(inputCol=\"smoker\",outputCol=\"smoker_indexed\")\n",
    "df_transformed = si.fit(df_transformed).transform(df_transformed)\n",
    "\n",
    "si = StringIndexer(inputCol=\"day\",outputCol=\"day_indexed\")\n",
    "df_transformed = si.fit(df_transformed).transform(df_transformed)\n",
    "\n",
    "si = StringIndexer(inputCol=\"time\",outputCol=\"time_indexed\")\n",
    "df_transformed = si.fit(df_transformed).transform(df_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d5b5a",
   "metadata": {},
   "source": [
    "**9. Display the DataFrame after applying the StringIndexer transformation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f663513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|smoker_indexed|day_indexed|time_indexed|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|           0.0|        1.0|         0.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|         0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|         0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|           0.0|        1.0|         0.0|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|        0.0|           0.0|        1.0|         0.0|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|        0.0|           0.0|        1.0|         0.0|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|        1.0|           0.0|        1.0|         0.0|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|        0.0|           0.0|        1.0|         0.0|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|        1.0|           0.0|        1.0|         0.0|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|        1.0|           0.0|        1.0|         0.0|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|         0.0|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|        1.0|           0.0|        1.0|         0.0|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|        0.0|           0.0|        0.0|         0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424440b",
   "metadata": {},
   "source": [
    "**10. Import the required class used to combine multiple feature columns into a single vector.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1c1e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b4f0a",
   "metadata": {},
   "source": [
    "**11. Write the statement used to create a VectorAssembler with the specified input and output columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00095472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+-----------+--------------+-----------+------------+\n",
      "|total_bill| tip|size|sex_indexed|smoker_indexed|day_indexed|time_indexed|\n",
      "+----------+----+----+-----------+--------------+-----------+------------+\n",
      "|     16.99|1.01|   2|        1.0|           0.0|        1.0|         0.0|\n",
      "|     10.34|1.66|   3|        0.0|           0.0|        1.0|         0.0|\n",
      "|     21.01| 3.5|   3|        0.0|           0.0|        1.0|         0.0|\n",
      "|     23.68|3.31|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     24.59|3.61|   4|        1.0|           0.0|        1.0|         0.0|\n",
      "|     25.29|4.71|   4|        0.0|           0.0|        1.0|         0.0|\n",
      "|      8.77| 2.0|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     26.88|3.12|   4|        0.0|           0.0|        1.0|         0.0|\n",
      "|     15.04|1.96|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     14.78|3.23|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     10.27|1.71|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     35.26| 5.0|   4|        1.0|           0.0|        1.0|         0.0|\n",
      "|     15.42|1.57|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     18.43| 3.0|   4|        0.0|           0.0|        1.0|         0.0|\n",
      "|     14.83|3.02|   2|        1.0|           0.0|        1.0|         0.0|\n",
      "|     21.58|3.92|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     10.33|1.67|   3|        1.0|           0.0|        1.0|         0.0|\n",
      "|     16.29|3.71|   3|        0.0|           0.0|        1.0|         0.0|\n",
      "|     16.97| 3.5|   3|        1.0|           0.0|        1.0|         0.0|\n",
      "|     20.65|3.35|   3|        0.0|           0.0|        0.0|         0.0|\n",
      "+----------+----+----+-----------+--------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tr = df_transformed.drop(\"sex\",\"smoker\",\"day\",\"time\")\n",
    "df_tr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c0421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = VectorAssembler(inputCols=[\"tip\",\"size\",\"sex_indexed\",\"smoker_indexed\",\"day_indexed\",\"time_indexed\"],outputCol=\"Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77399264",
   "metadata": {},
   "source": [
    "**12. Write the command used to transform the DataFrame using the VectorAssembler.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09387333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|               Input|total_bill|\n",
      "+--------------------+----------+\n",
      "|[1.01,2.0,1.0,0.0...|     16.99|\n",
      "|[1.66,3.0,0.0,0.0...|     10.34|\n",
      "|[3.5,3.0,0.0,0.0,...|     21.01|\n",
      "|[3.31,2.0,0.0,0.0...|     23.68|\n",
      "|[3.61,4.0,1.0,0.0...|     24.59|\n",
      "|[4.71,4.0,0.0,0.0...|     25.29|\n",
      "|[2.0,2.0,0.0,0.0,...|      8.77|\n",
      "|[3.12,4.0,0.0,0.0...|     26.88|\n",
      "|[1.96,2.0,0.0,0.0...|     15.04|\n",
      "|[3.23,2.0,0.0,0.0...|     14.78|\n",
      "|[1.71,2.0,0.0,0.0...|     10.27|\n",
      "|[5.0,4.0,1.0,0.0,...|     35.26|\n",
      "|[1.57,2.0,0.0,0.0...|     15.42|\n",
      "|[3.0,4.0,0.0,0.0,...|     18.43|\n",
      "|[3.02,2.0,1.0,0.0...|     14.83|\n",
      "|[3.92,2.0,0.0,0.0...|     21.58|\n",
      "|[1.67,3.0,1.0,0.0...|     10.33|\n",
      "|[3.71,3.0,0.0,0.0...|     16.29|\n",
      "|[3.5,3.0,1.0,0.0,...|     16.97|\n",
      "|(6,[0,1],[3.35,3.0])|     20.65|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_assembled = vect.transform(df_transformed)\n",
    "df_assembled = df_assembled.select(\"Input\",\"total_bill\")\n",
    "df_assembled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a269e0",
   "metadata": {},
   "source": [
    "**13. Import the PySpark ML class required to perform Linear Regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57182f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00aa22",
   "metadata": {},
   "source": [
    "**14. Write the statement used to create a Linear Regression model by specifying the features and label columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5051d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = df_assembled.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aa57982",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"Input\",labelCol=\"total_bill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e39a26",
   "metadata": {},
   "source": [
    "**15. Write the command used to fit (train) the Linear Regression model on the transformed DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23f90a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157ea3d",
   "metadata": {},
   "source": [
    "**16. Write the statement used to display the coefficients and intercept of the trained Linear Regression model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22769696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3897165943664183,3.7905896378496933,-1.7462909858374005,2.505548757099815,0.44337965858913725,-1.0523555389638801]\n",
      "-0.7592520766369085\n"
     ]
    }
   ],
   "source": [
    "print(model.coefficients)\n",
    "print(model.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5108a",
   "metadata": {},
   "source": [
    "**17. Write the command used to generate predictions using the trained model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74e6a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64734ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+\n",
      "|               Input|total_bill|        prediction|\n",
      "+--------------------+----------+------------------+\n",
      "|(6,[0,1],[1.25,2.0])|     10.51|11.059072942020501|\n",
      "| (6,[0,1],[2.0,3.0])|     16.31|17.391950025645006|\n",
      "|(6,[0,1],[2.01,2.0])|     20.23|13.635257553738978|\n",
      "|(6,[0,1],[2.24,3.0])|     16.04| 18.20548200829295|\n",
      "| (6,[0,1],[3.6,3.0])|     24.06| 22.81549657663128|\n",
      "|[1.1,2.0,1.0,1.0,...|      12.9|11.309873224127953|\n",
      "|[1.17,2.0,0.0,1.0...|     32.83|13.293444371571002|\n",
      "|[1.5,2.0,0.0,0.0,...|     19.08|11.740905868826498|\n",
      "|[1.5,2.0,1.0,0.0,...|     26.41|10.160211104774703|\n",
      "|[1.5,2.0,1.0,0.0,...|      8.35| 9.994614882989097|\n",
      "|[1.5,2.0,1.0,0.0,...|     11.17| 9.994614882989097|\n",
      "|[1.58,2.0,0.0,1.0...|     13.42|14.961011612064766|\n",
      "|[1.63,2.0,1.0,0.0...|     11.87|10.435278040256733|\n",
      "|[1.67,3.0,1.0,0.0...|     10.33|14.970432222255823|\n",
      "|[1.8,2.0,1.0,0.0,...|     12.43|11.011529861299024|\n",
      "|[1.96,2.0,0.0,0.0...|     15.04|13.909151382609796|\n",
      "|[2.0,2.0,0.0,1.0,...|     13.51|15.941312923109525|\n",
      "|[2.0,2.0,1.0,0.0,...|     12.26|11.689473180172307|\n",
      "|[2.0,2.0,1.0,0.0,...|     14.52|11.689473180172307|\n",
      "|[2.0,2.0,1.0,1.0,...|     27.18|14.360618159057728|\n",
      "+--------------------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(test_df)\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a0c528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pred.withColumn(\"prediction\",round(col(\"prediction\"),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75fa96",
   "metadata": {},
   "source": [
    "**18. Display the output DataFrame containing the prediction results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d30e8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+\n",
      "|               Input|total_bill|prediction|\n",
      "+--------------------+----------+----------+\n",
      "|(6,[0,1],[1.25,2.0])|     10.51|     11.06|\n",
      "| (6,[0,1],[2.0,3.0])|     16.31|     17.39|\n",
      "|(6,[0,1],[2.01,2.0])|     20.23|     13.64|\n",
      "|(6,[0,1],[2.24,3.0])|     16.04|     18.21|\n",
      "| (6,[0,1],[3.6,3.0])|     24.06|     22.82|\n",
      "|[1.1,2.0,1.0,1.0,...|      12.9|     11.31|\n",
      "|[1.17,2.0,0.0,1.0...|     32.83|     13.29|\n",
      "|[1.5,2.0,0.0,0.0,...|     19.08|     11.74|\n",
      "|[1.5,2.0,1.0,0.0,...|     26.41|     10.16|\n",
      "|[1.5,2.0,1.0,0.0,...|      8.35|      9.99|\n",
      "|[1.5,2.0,1.0,0.0,...|     11.17|      9.99|\n",
      "|[1.58,2.0,0.0,1.0...|     13.42|     14.96|\n",
      "|[1.63,2.0,1.0,0.0...|     11.87|     10.44|\n",
      "|[1.67,3.0,1.0,0.0...|     10.33|     14.97|\n",
      "|[1.8,2.0,1.0,0.0,...|     12.43|     11.01|\n",
      "|[1.96,2.0,0.0,0.0...|     15.04|     13.91|\n",
      "|[2.0,2.0,0.0,1.0,...|     13.51|     15.94|\n",
      "|[2.0,2.0,1.0,0.0,...|     12.26|     11.69|\n",
      "|[2.0,2.0,1.0,0.0,...|     14.52|     11.69|\n",
      "|[2.0,2.0,1.0,1.0,...|     27.18|     14.36|\n",
      "+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0884bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22069613856137815\n",
      "5.0395571390168055\n",
      "47.75407505796078\n",
      "6.910432335097478\n"
     ]
    }
   ],
   "source": [
    "pred_results=model.evaluate(test_df)\n",
    "\n",
    "print(pred_results.r2)\n",
    "print(pred_results.meanAbsoluteError)\n",
    "print(pred_results.meanSquaredError)\n",
    "print(pred_results.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1ce9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47eb80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session (connects to cluster)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Distributed Log Processing\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c7115ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample log data (in reality this would be huge & stored in HDFS/S3)\n",
    "data = [\n",
    "    (\"2026-01-01\", \"/home\"),\n",
    "    (\"2026-01-01\", \"/login\"),\n",
    "    (\"2026-01-01\", \"/home\"),\n",
    "    (\"2026-01-02\", \"/products\"),\n",
    "    (\"2026-01-02\", \"/home\"),\n",
    "]\n",
    "\n",
    "columns = [\"date\", \"url\"]\n",
    "\n",
    "# Create DataFrame\n",
    "logs_df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb2869b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed aggregation\n",
    "url_counts = logs_df.groupBy(\"url\").agg(count(\"*\").alias(\"request_count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fe3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action triggers distributed execution\n",
    "url_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44c13f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
