{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-28T23:56:04.355543900Z",
     "start_time": "2024-01-28T23:56:04.326909700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageFilter\n",
    "import pytesseract\n",
    "from scipy.ndimage import *\n",
    "import scipy.signal as scisignal\n",
    "import skimage.exposure as expo\n",
    "import skimage.morphology as morpha\n",
    "from skimage.measure import *\n",
    "import scipy.ndimage as ndimg\n",
    "import supported_functions as sf\n",
    "import create_templates as ct"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aspect_ratio = lambda image: image.size[0] / image.size[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T23:56:05.009588Z",
     "start_time": "2024-01-28T23:56:05.000998200Z"
    }
   },
   "id": "3cdadad22925f6fa",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import image\n",
    "image = Image.open(\"data/71tfK2KxQ-L._AC_SX466_.jpg\")\n",
    "\n",
    "# Resize the image while maintaining aspect ratio\n",
    "new_size_of_image = (400,round(400/aspect_ratio(image)))\n",
    "new_image = image.resize(new_size_of_image)\n",
    "\n",
    "# Convert Image to Grayscale (Colour Image Processing)\n",
    "image_grayscale = new_image.convert(\"L\")\n",
    "\n",
    "# Perform median filtering on the image\n",
    "median_filtered_image = image_grayscale.filter(ImageFilter.MedianFilter(3))\n",
    "\n",
    "# Structural element for image dilation and erosion\n",
    "structural_element = np.array([[0,1,0],\n",
    "                      [1,1,1],\n",
    "                      [0,1,0]])\n",
    "\n",
    "# Converting median filtered image to its binary form for image dilation and erosion\n",
    "binary_image = median_filtered_image.convert(\"1\")\n",
    "\n",
    "# Performing Image Dilation using the structural element\n",
    "dilated_image = np.int64(ndimg.binary_dilation(input=binary_image,structure=structural_element))\n",
    "\n",
    "# Performing Image Erosion using the structural element\n",
    "eroded_image = np.int64(ndimg.binary_erosion(input=binary_image,structure=structural_element))\n",
    "\n",
    "# Morphological Element for enhancing edges of the image\n",
    "gradient_image = dilated_image - eroded_image\n",
    "\n",
    "# Scaling the image to [0,1] to convert the image to double precision\n",
    "gradient_image_scaled = gradient_image / gradient_image.max()\n",
    "\n",
    "# Convolution of double precision image for beightening the edges\n",
    "kernel = [[1,1],\n",
    "          [1,1]]\n",
    "convolved_image = scisignal.convolve2d(in1=gradient_image_scaled,in2=kernel,mode=\"valid\")\n",
    "\n",
    "# Intensity scaling between the range 0 to 1\n",
    "low_in = 0.5\n",
    "high_in = 0.7\n",
    "low_out = 0\n",
    "high_out = 1\n",
    "gamma = 0.1\n",
    "gain = (high_out - low_out) / (high_in - low_in)\n",
    "intensity_scaled_image = expo.adjust_gamma(image=convolved_image,gamma=gamma,gain=gain)\n",
    "\n",
    "# Conversion of double image back to binary image\n",
    "back_binary_image = np.round(intensity_scaled_image / intensity_scaled_image.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T23:56:05.440620Z",
     "start_time": "2024-01-28T23:56:05.391403200Z"
    }
   },
   "id": "d80c1f5ffc07f297",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 1., 1., ..., 1., 1., 1.],\n       [1., 0., 0., ..., 0., 0., 1.],\n       [1., 0., 0., ..., 0., 0., 1.],\n       ...,\n       [1., 0., 0., ..., 0., 0., 1.],\n       [1., 0., 0., ..., 0., 0., 1.],\n       [1., 1., 1., ..., 1., 1., 1.]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_binary_image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T23:56:05.980638300Z",
     "start_time": "2024-01-28T23:56:05.935039100Z"
    }
   },
   "id": "5c8b532d10a38df9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Elimination of edges of the licence plate\n",
    "\n",
    "eroded_back_binary_image = np.float64(ndimg.binary_erosion(input=back_binary_image,structure=np.ones(shape=(1,50))))\n",
    "eliminated_edges_image = back_binary_image - eroded_back_binary_image\n",
    "\n",
    "# Filling all the regions of the image with holes\n",
    "eliminated_edges_image_inverted = 1 - eliminated_edges_image\n",
    "filled_image_with_holes_before_invert = ndimg.binary_fill_holes(eliminated_edges_image_inverted)\n",
    "filled_image_with_holes = 1 - filled_image_with_holes_before_invert\n",
    "\n",
    "# Thinning the image filled with holes to make sure that characters do not match with each other (THIS STEP IS THE ACTUAL STEP FOR MORPHOLOGICAL PROCESSING\n",
    "thinned_image = np.float64(morpha.thin(filled_image_with_holes))\n",
    "eroded_thinned_image = np.float64(ndimg.binary_erosion(input=thinned_image,structure=np.ones(shape=(3,1))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T23:56:07.432400Z",
     "start_time": "2024-01-28T23:56:07.330753600Z"
    }
   },
   "id": "e34922f95f951633",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Selecting all the pixels of area more than 100 (Image masking)\n",
    "image_with_labels, number_of_labels = ndimg.label(eroded_thinned_image)\n",
    "area_of_each_component = np.bincount(image_with_labels.ravel())\n",
    "mask_with_pixel_areas_greater_than_100 = area_of_each_component >= 100\n",
    "image_with_pixel_areas_greater_than_100 = np.float64(mask_with_pixel_areas_greater_than_100[image_with_labels])\n",
    "final_image_for_vehicle_number_detection = np.int64(image_with_pixel_areas_greater_than_100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T23:56:08.314773Z",
     "start_time": "2024-01-28T23:56:08.294289400Z"
    }
   },
   "id": "1590aa6925252a4b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Considering two properties of image regions: 1) \"Bounding Boxes\" and 2) \"Binary Images\" corresponding to Bounding Images\n",
    "image_region_properties = regionprops(final_image_for_vehicle_number_detection)\n",
    "\n",
    "# Considering the bounding boxes in a matrix of order <Number of Bounding Boxes> X 4;\n",
    "bounding_boxes = np.vstack([i.bbox for i in image_region_properties])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T23:56:08.934857700Z",
     "start_time": "2024-01-28T23:56:08.922371200Z"
    }
   },
   "id": "d1a2a5e5567ada15",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 33 and the array at index 1 has size 17",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m cc \u001B[38;5;241m=\u001B[39m \u001B[43mct\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_templates\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\mvsr-data-scientist\\Detection of Vehicle Number on Licence Plate\\create_templates.py:90\u001B[0m, in \u001B[0;36mcreate_templates\u001B[1;34m()\u001B[0m\n\u001B[0;32m     87\u001B[0m number_resized \u001B[38;5;241m=\u001B[39m [resize_image(img, target_height) \u001B[38;5;28;01mfor\u001B[39;00m img \u001B[38;5;129;01min\u001B[39;00m number]\n\u001B[0;32m     89\u001B[0m \u001B[38;5;66;03m# Concatenate resized arrays\u001B[39;00m\n\u001B[1;32m---> 90\u001B[0m character \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mletter_resized\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_resized\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;66;03m# Reshape to create templates\u001B[39;00m\n\u001B[0;32m     93\u001B[0m NewTemplates \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msplit(character, \u001B[38;5;241m42\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 33 and the array at index 1 has size 17"
     ]
    }
   ],
   "source": [
    "cc = ct.create_templates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T23:57:16.388608900Z",
     "start_time": "2024-01-28T23:57:16.318812900Z"
    }
   },
   "id": "d6a98df2f14acfbd",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Retrieving an array comprising the indices for bounding boxes needed for character extraction\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m character_extraction_bounding_box_indices \u001B[38;5;241m=\u001B[39m \u001B[43msf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontrolling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbounding_boxes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\mvsr-data-scientist\\Detection of Vehicle Number on Licence Plate\\supported_functions.py:36\u001B[0m, in \u001B[0;36mcontrolling\u001B[1;34m(NR)\u001B[0m\n\u001B[0;32m     34\u001B[0m     r \u001B[38;5;241m=\u001B[39m takeboxes(NR, container, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 36\u001B[0m     container \u001B[38;5;241m=\u001B[39m \u001B[43mguessthesix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mB\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mB\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m container:\n\u001B[0;32m     38\u001B[0m         r \u001B[38;5;241m=\u001B[39m takeboxes(NR, container, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\mvsr-data-scientist\\Detection of Vehicle Number on Licence Plate\\supported_functions.py:52\u001B[0m, in \u001B[0;36mguessthesix\u001B[1;34m(Q, W, bsize)\u001B[0m\n\u001B[0;32m     50\u001B[0m var \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(val)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m var \u001B[38;5;129;01mor\u001B[39;00m var \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 52\u001B[0m     index \u001B[38;5;241m=\u001B[39m val[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mval\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m val[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(Q):\n\u001B[0;32m     54\u001B[0m         index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Retrieving an array comprising the indices for bounding boxes needed for character extraction\n",
    "character_extraction_bounding_box_indices = sf.controlling(bounding_boxes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:35:00.722691400Z",
     "start_time": "2024-01-28T18:35:00.668517200Z"
    }
   },
   "id": "3d655831f79f11da",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5ac68806d9b50882"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
